from typing import Dict, List, Any, Optional
import asyncio

from langchain_core.tools import tool
from langchain_core.messages import SystemMessage, HumanMessage

from app.ai.agents import qamaker_agent, interviewer_agent, evaluator_agent
# from app.core.config import settings

# -------------------------------------------------------------------------
# MCP Tools Definition
# Main Agent acts as a provider/registry of these tools.
# -------------------------------------------------------------------------

@tool("generate_questions", description="Generate interview questions based on topic and difficulty level.")
async def generate_questions(topic: str, level: str, count: int = 1) -> List[Dict[str, Any]]:
    """
    Generate interview questions based on a topic and difficulty level.
    Use this tool when the user wants to start a new quiz or interview session.
    """
    print(f"ğŸ•µï¸â€â™‚ï¸ [Tool:generate_questions] Generating {count} questions for {topic} ({level})...")
    
    tasks = [
        qamaker_agent.generate_single_question(skill=topic, topic=topic, level=level) 
        for _ in range(count)
    ]
    
    results = await asyncio.gather(*tasks)
    return results


@tool("evaluate_answer", description="Evaluate user Answer and decide Next Action (PASS/DEEP_DIVE).")
async def evaluate_answer(question: str, user_answer: str, level: str) -> Dict[str, Any]:
    """
    Evaluate the user's answer and decide the next course of action.
    Use this tool immediately after the user provides an answer to an interview question.
    """
    print(f"ğŸ¤” [Tool:evaluate_answer] Evaluating answer for {level}...")

    # Reuse evaluator agent logic
    eval_result = await evaluator_agent.evaluate_answer(
        question=question,
        user_answer=user_answer,
        model_answer="N/A", 
        evaluation_criteria=[f"Level: {level}"]
    )
    
    is_pass = eval_result.get("is_passed", False)
    next_action = "PASS" if is_pass else "DEEP_DIVE"
    
    return {
        "score": eval_result.get("score", 0),
        "feedback": eval_result.get("feedback", ""),
        "is_pass": is_pass,
        "next_action": next_action
    }


@tool("generate_followup", description="Generate a sharp follow-up question for deep dive.")
async def generate_followup(previous_question: str, user_answer: str, level: str) -> str:
    """
    Generate a follow-up (deep dive) question when the user's answer requires further probing.
    Use this tool when 'evaluate_answer' returns 'next_action' as 'DEEP_DIVE'.
    """
    context_prompt = f"""
    [ìƒí™©]
    - ì´ì „ ì§ˆë¬¸: {previous_question}
    - ì‚¬ìš©ì ë‹µë³€: {user_answer}
    - ë ˆë²¨: {level}
    
    ì‚¬ìš©ìì˜ ë‹µë³€ì´ ë¶€ì¡±í•˜ê±°ë‚˜ ë” ê²€ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤. 
    ê´€ë ¨ëœ ê°œë…ì˜ íŠ¸ë ˆì´ë“œì˜¤í”„ë‚˜ ì—£ì§€ ì¼€ì´ìŠ¤ë¥¼ ë¬»ëŠ” ë‚ ì¹´ë¡œìš´ 'ê¼¬ë¦¬ ì§ˆë¬¸(Follow-up)'ì„ í•˜ë‚˜ë§Œ ìƒì„±í•˜ì„¸ìš”.
    """
    
    followup_q = await interviewer_agent.generate_interview_response(
        user_input=context_prompt,
        history=[] 
    )
    
    return followup_q


@tool("summarize_result", description="Analyze conversation logic and generate a final report.")
async def summarize_result(conversation_history: List[str]) -> str:
    """
    Analyze the full conversation history and generate a comprehensive final report.
    Use this tool when the interview session is finished.
    """
    full_log = "\n".join(conversation_history)
    
    report_prompt = f"""
    ë‹¹ì‹ ì€ AI TechTreeì˜ ìµœì¢… í‰ê°€ê´€ì…ë‹ˆë‹¤.
    ë‹¤ìŒ ì¸í„°ë·° ë¡œê·¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¢…í•© ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
    
    [ë¡œê·¸]
    {full_log}
    
    [ì¶œë ¥ í˜•ì‹]
    Markdown í¬ë§·ìœ¼ë¡œ ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨:
    1. ì¢…í•© ì ìˆ˜ ë° ë“±ê¸‰
    2. ê°•ì  (Strengths)
    3. ë³´ì™„ì  (Weaknesses)
    4. í–¥í›„ í•™ìŠµ ê°€ì´ë“œ
    """
    
    # Direct invocation of Evaluator LLM
    response = await evaluator_agent.llm.ainvoke([HumanMessage(content=report_prompt)])
    
    return response.content

# List of tools exported for easy registration
TOOLS = [generate_questions, evaluate_answer, generate_followup, summarize_result]

